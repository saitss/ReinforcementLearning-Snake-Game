{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#max 27\n",
    "#sonra devam et\n",
    "#env değiştirildi. \n",
    "#best snakes so far tmp/Actor_v2.0-copy1-savepoint3 tmp/Critic_v2.0-copy1-savepoint3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from envwithheart.ipynb\n",
      "-0.1\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import import_ipynb\n",
    "from envwithheart import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "env=environement()\n",
    "info={}\n",
    "env.env_init(info)\n",
    "\n",
    "class a2c_v2:\n",
    "    def __init__(self, info={}):\n",
    "        self.n_actions = info.get(\"n_actions\",4) \n",
    "        self.input_shape=info.get(\"input_shape\",(12,12,2)) \n",
    "        self.EPISODES = info.get(\"episodes\",100000) \n",
    "        self.lr = info.get(\"lr\",0.001) \n",
    "        self.gamma=info.get(\"gamma\",0.99)\n",
    "        self.Actor, self.Critic = self.create_model(input_shape=self.input_shape, n_actions=self.n_actions, lr=self.lr)\n",
    "        self.states, self.actions, self.rewards = [], [], []\n",
    "        \n",
    "    def create_model(self,input_shape,n_actions,lr):\n",
    "        inputs= keras.Input(shape=input_shape)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\",padding=\"same\")(inputs)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\",padding=\"same\")(x)\n",
    "        block_1_output = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\",padding=\"same\")(block_1_output)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\",padding=\"same\")(x)\n",
    "        x = layers.add([x, block_1_output])\n",
    "        x=layers.Flatten()(x)\n",
    "        action = layers.Dense(n_actions, activation=\"softmax\")(x)\n",
    "        value = layers.Dense(1)(x)\n",
    "\n",
    "        Actor = keras.Model(inputs = inputs, outputs = action)\n",
    "        Actor.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(lr=lr))\n",
    "\n",
    "        Critic = keras.Model(inputs = inputs, outputs = value)\n",
    "        Critic.compile(loss='mse', optimizer=keras.optimizers.RMSprop(lr=lr))\n",
    "\n",
    "        return Actor, Critic\n",
    "    def remember(self, state, action, reward):\n",
    "        self.states.append(np.reshape(state,(1,12,12,2)))\n",
    "        action_onehot = np.zeros([self.n_actions])\n",
    "        action_onehot[action] = 1\n",
    "        self.actions.append(action_onehot)\n",
    "        self.rewards.append(reward)\n",
    "    def act(self, state):\n",
    "        prediction = self.Actor.predict(np.reshape(state,(1,12,12,2)))[0]\n",
    "        #print(prediction)\n",
    "        action = np.random.choice(self.n_actions, p=prediction)\n",
    "        return action\n",
    "    def discount_rewards(self, reward,states):\n",
    "        gamma=0.01*env.length    # discount rate\n",
    "        running_add = 0\n",
    "        discounted_r = np.zeros_like(reward,dtype=float)\n",
    "        for i in reversed(range(0,len(reward))):\n",
    "            running_add = running_add * gamma + reward[i]\n",
    "            discounted_r[i] = running_add\n",
    "        return discounted_r\n",
    "\n",
    "        \n",
    "    def replay(self):\n",
    "        states = np.vstack(self.states)\n",
    "        actions = np.vstack(self.actions)\n",
    "        discounted_r = self.discount_rewards(self.rewards,states)\n",
    "        values = self.Critic.predict(states)[:, 0]\n",
    "        advantages = discounted_r - values\n",
    "        # training Actor and Critic networks\n",
    "        self.Actor.fit(states, actions, sample_weight=advantages, epochs=1, verbose=0)\n",
    "        self.Critic.fit(states, discounted_r, epochs=1, verbose=0)\n",
    "        self.states, self.actions, self.rewards = [], [], []\n",
    "    def step(self, action):\n",
    "        reward, next_state, done,score = env.step(action)\n",
    "        #print(next_state[:,:,0])\n",
    "        return next_state, reward, done,score\n",
    "    def run(self):\n",
    "        for e in range(self.EPISODES):\n",
    "            state = env.start()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done,score= self.step(action)\n",
    "                self.remember(state, action, reward)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    print(\"Episode :\",e,\" Score :\",score)\n",
    "                    if(e%1000==0):\n",
    "                        self.save()\n",
    "                    self.replay()\n",
    "    def save(self):\n",
    "        self.Actor.save('tmp/Actorstardeneme')\n",
    "        self.Critic.save('tmp/Criticstardeneme')\n",
    "    def load(self):\n",
    "        self.Actor = tf.keras.models.load_model('tmp/Actorstardeneme')\n",
    "        self.Critic = tf.keras.models.load_model('tmp/Criticstardeneme')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12, 12, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 12, 12, 64)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 12, 12, 64)   36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 6, 6, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 6, 6, 64)     36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 64)     36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 6, 6, 64)     0           conv2d_3[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2304)         0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2305        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 114,305\n",
      "Trainable params: 114,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a=a2c_v2()\n",
    "a.Critic.summary()\n",
    "a.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 0  Score : 16\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: tmp/Actorstardeneme\\assets\n",
      "INFO:tensorflow:Assets written to: tmp/Criticstardeneme\\assets\n",
      "Episode : 1  Score : 12\n",
      "Episode : 2  Score : 0\n",
      "Episode : 3  Score : 0\n",
      "Episode : 4  Score : 0\n",
      "Episode : 5  Score : 0\n",
      "Episode : 6  Score : 0\n",
      "Episode : 7  Score : 0\n",
      "Episode : 8  Score : 0\n",
      "Episode : 9  Score : 0\n",
      "Episode : 10  Score : 0\n",
      "Episode : 11  Score : 0\n",
      "Episode : 12  Score : 0\n",
      "Episode : 13  Score : 0\n",
      "Episode : 14  Score : 0\n",
      "Episode : 15  Score : 0\n",
      "Episode : 16  Score : 0\n",
      "Episode : 17  Score : 0\n",
      "Episode : 18  Score : 0\n",
      "Episode : 19  Score : 0\n",
      "Episode : 20  Score : 0\n",
      "Episode : 21  Score : 0\n",
      "Episode : 22  Score : 0\n",
      "Episode : 23  Score : 0\n",
      "Episode : 24  Score : 0\n",
      "Episode : 25  Score : 0\n",
      "Episode : 26  Score : 0\n",
      "Episode : 27  Score : 0\n",
      "Episode : 28  Score : 0\n",
      "Episode : 29  Score : 0\n",
      "Episode : 30  Score : 0\n",
      "Episode : 31  Score : 0\n",
      "Episode : 32  Score : 0\n",
      "Episode : 33  Score : 1\n",
      "Episode : 34  Score : 0\n",
      "Episode : 35  Score : 0\n",
      "Episode : 36  Score : 0\n",
      "Episode : 37  Score : 0\n",
      "Episode : 38  Score : 0\n",
      "Episode : 39  Score : 0\n",
      "Episode : 40  Score : 0\n",
      "Episode : 41  Score : 0\n",
      "Episode : 42  Score : 0\n",
      "Episode : 43  Score : 0\n",
      "Episode : 44  Score : 0\n",
      "Episode : 45  Score : 0\n",
      "Episode : 46  Score : 0\n",
      "Episode : 47  Score : 1\n",
      "Episode : 48  Score : 0\n",
      "Episode : 49  Score : 0\n",
      "Episode : 50  Score : 0\n",
      "Episode : 51  Score : 0\n",
      "Episode : 52  Score : 0\n",
      "Episode : 53  Score : 0\n",
      "Episode : 54  Score : 0\n",
      "Episode : 55  Score : 0\n",
      "Episode : 56  Score : 0\n",
      "Episode : 57  Score : 0\n",
      "Episode : 58  Score : 0\n",
      "Episode : 59  Score : 0\n",
      "Episode : 60  Score : 0\n",
      "Episode : 61  Score : 0\n",
      "Episode : 62  Score : 0\n",
      "Episode : 63  Score : 0\n",
      "Episode : 64  Score : 0\n",
      "Episode : 65  Score : 0\n",
      "Episode : 66  Score : 0\n",
      "Episode : 67  Score : 0\n",
      "Episode : 68  Score : 1\n",
      "Episode : 69  Score : 0\n",
      "Episode : 70  Score : 0\n",
      "Episode : 71  Score : 0\n",
      "Episode : 72  Score : 0\n",
      "Episode : 73  Score : 0\n",
      "Episode : 74  Score : 0\n",
      "Episode : 75  Score : 0\n",
      "Episode : 76  Score : 0\n",
      "Episode : 77  Score : 0\n",
      "Episode : 78  Score : 0\n",
      "Episode : 79  Score : 0\n",
      "Episode : 80  Score : 0\n",
      "Episode : 81  Score : 0\n",
      "Episode : 82  Score : 0\n",
      "Episode : 83  Score : 0\n",
      "Episode : 84  Score : 0\n",
      "Episode : 85  Score : 0\n",
      "Episode : 86  Score : 0\n",
      "Episode : 87  Score : 0\n",
      "Episode : 88  Score : 0\n",
      "Episode : 89  Score : 1\n",
      "Episode : 90  Score : 1\n",
      "Episode : 91  Score : 1\n",
      "Episode : 92  Score : 0\n",
      "Episode : 93  Score : 0\n",
      "Episode : 94  Score : 1\n",
      "Episode : 95  Score : 0\n",
      "Episode : 96  Score : 2\n",
      "Episode : 97  Score : 1\n",
      "Episode : 98  Score : 0\n",
      "Episode : 99  Score : 1\n",
      "Episode : 100  Score : 2\n",
      "Episode : 101  Score : 0\n",
      "Episode : 102  Score : 1\n",
      "Episode : 103  Score : 0\n",
      "Episode : 104  Score : 5\n",
      "Episode : 105  Score : 0\n",
      "Episode : 106  Score : 2\n",
      "Episode : 107  Score : 1\n",
      "Episode : 108  Score : 1\n",
      "Episode : 109  Score : 0\n",
      "Episode : 110  Score : 2\n",
      "Episode : 111  Score : 1\n",
      "Episode : 112  Score : 2\n",
      "Episode : 113  Score : 1\n",
      "Episode : 114  Score : 1\n",
      "Episode : 115  Score : 0\n",
      "Episode : 116  Score : 0\n",
      "Episode : 117  Score : 0\n",
      "Episode : 118  Score : 1\n",
      "Episode : 119  Score : 0\n",
      "Episode : 120  Score : 5\n",
      "Episode : 121  Score : 0\n",
      "Episode : 122  Score : 3\n",
      "Episode : 123  Score : 1\n",
      "Episode : 124  Score : 1\n",
      "Episode : 125  Score : 3\n",
      "Episode : 126  Score : 3\n",
      "Episode : 127  Score : 2\n",
      "Episode : 128  Score : 0\n",
      "Episode : 129  Score : 1\n",
      "Episode : 130  Score : 1\n",
      "Episode : 131  Score : 0\n",
      "Episode : 132  Score : 9\n",
      "Episode : 133  Score : 15\n",
      "Episode : 134  Score : 4\n",
      "Episode : 135  Score : 12\n",
      "Episode : 136  Score : 23\n",
      "Episode : 137  Score : 5\n",
      "Episode : 138  Score : 18\n",
      "Episode : 139  Score : 12\n",
      "Episode : 140  Score : 10\n",
      "Episode : 141  Score : 12\n",
      "Episode : 142  Score : 18\n",
      "Episode : 143  Score : 10\n",
      "Episode : 144  Score : 6\n",
      "Episode : 145  Score : 6\n",
      "Episode : 146  Score : 4\n",
      "Episode : 147  Score : 10\n",
      "Episode : 148  Score : 14\n",
      "Episode : 149  Score : 6\n",
      "Episode : 150  Score : 9\n",
      "Episode : 151  Score : 7\n",
      "Episode : 152  Score : 2\n",
      "Episode : 153  Score : 2\n",
      "Episode : 154  Score : 1\n",
      "Episode : 155  Score : 13\n",
      "Episode : 156  Score : 5\n",
      "Episode : 157  Score : 13\n",
      "Episode : 158  Score : 15\n",
      "Episode : 159  Score : 11\n",
      "Episode : 160  Score : 10\n",
      "Episode : 161  Score : 12\n",
      "Episode : 162  Score : 7\n",
      "Episode : 163  Score : 4\n",
      "Episode : 164  Score : 6\n",
      "Episode : 165  Score : 4\n",
      "Episode : 166  Score : 12\n",
      "Episode : 167  Score : 0\n",
      "Episode : 168  Score : 12\n",
      "Episode : 169  Score : 9\n",
      "Episode : 170  Score : 17\n",
      "Episode : 171  Score : 20\n",
      "Episode : 172  Score : 13\n",
      "Episode : 173  Score : 14\n",
      "Episode : 174  Score : 6\n",
      "Episode : 175  Score : 6\n",
      "Episode : 176  Score : 13\n",
      "Episode : 177  Score : 6\n",
      "Episode : 178  Score : 9\n",
      "Episode : 179  Score : 6\n",
      "Episode : 180  Score : 4\n",
      "Episode : 181  Score : 12\n",
      "Episode : 182  Score : 9\n",
      "Episode : 183  Score : 13\n",
      "Episode : 184  Score : 8\n",
      "Episode : 185  Score : 10\n",
      "Episode : 186  Score : 13\n",
      "Episode : 187  Score : 8\n",
      "Episode : 188  Score : 14\n"
     ]
    }
   ],
   "source": [
    "a.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
